---
title: "Introduction"
description: "An introduction to mechanistic interpretability and the Neuronpedia platform."
---

### Mechanistic Interpretability

Mechanistic interpretability addresses the fundamental problem of reverse‑engineering a trained network’s computational circuits. The goal is to factor the model’s enigimatic dynamics into human‑interpretable algorithms: mapping internal representations, linear transformations, and nonlinear activations into a causal graph of computations. By reconstructing these circuits, we adapt a "black‑box" parameterization into an auditable system whose logic can be instrumented, verified, and formally reasoned about.

### Neuronpedia

Neuronpedia is an open‑source platform designed to operationalize this agenda. It ships a robustly engineered toolkit that lets researchers, production ML teams, and even curious hobbyists conduct analyses at scale. 

### Find your use case

<CardGroup cols={2}>
  <Card title="Data" icon="database">
    A flexible data layer that lets you tap into terabytes of public vectors, upload your own, and compile custom activation lists for large‑scale interpretability work.
  </Card>
  <Card title="Auto-Interp" icon="brain">
    An automated pipeline that explains and scores activations - on demand or in batch - using multiple large models and extensible methods.
  </Card>
  <Card title="API" icon="gear">
    A fully‑featured interface (with Python and TypeScript SDKs) that exposes every Neuronpedia capability for effortless integration into your workflows.
  </Card>
  <Card title="Search + Filter" icon="filter">
    Precision tools for finding the most relevant neurons or features by text, top‑K activations, or auto‑generated explanations across massive corpora.
  </Card>
  <Card title="Browse + Explore" icon="binoculars">
    Interactive dashboards and UMAP visualisations that turn raw vector spaces into navigable maps, enabling live activation testing and community annotations.
  </Card>
  <Card title="Steer Models" icon="sparkles">
    A control hub where you can inject custom steering vectors or tweak temperatures, penalties, and seeds to guide default, instruct, or reasoning models (and share the results).
  </Card>
  <Card title="Miscellaneous" icon="sparkles">
    Supporting resources - including SAE‑Bench visualisations and guided tutorials - that help you benchmark performance and deepen your interpretability know‑how.
  </Card>
</CardGroup>

With Neuronpedia you can move from opaque weights to actionable insights in hours, not weeks. Audit a model before deployment, debug mis‑fires in production, or publish reproducible interpretability papers, all without building bespoke tooling. Please feel free to reach out to us if you have any questions or feedback - we'd be happy to hear from you\!